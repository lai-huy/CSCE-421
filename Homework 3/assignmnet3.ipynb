{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08db0543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typeguard import typechecked\n",
    "import random\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from typing import Tuple, List, Optional, Any, Callable, Dict, Union\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564ad576",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c538a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@typechecked\n",
    "def read_data(filename: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read the data from the filename. Load the data it in a dataframe and return it.\n",
    "    \"\"\"\n",
    "    data: pd.DataFrame = pd.read_csv(filename)\n",
    "    data = data.dropna()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741f0e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@typechecked\n",
    "def data_preprocess(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Follow all the preprocessing steps mentioned in Problem 2 of HW2 (Problem 2: Coding: Preprocessing the Data.)\n",
    "    Return the final features and final label in same order\n",
    "    You may use the same code you submiited for problem 2 of HW2\n",
    "    \"\"\"\n",
    "    df_numerical: pd.DataFrame = df.select_dtypes(include=['int64', 'float64'])\n",
    "    df_categorical: pd.DataFrame = df.select_dtypes(\n",
    "        exclude=['int64', 'float64'])\n",
    "    df_categorical = pd.get_dummies(df_categorical)\n",
    "\n",
    "    return pd.concat([df_categorical, df_numerical], axis=1), pd.Series(df['NewLeague'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8485d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@typechecked\n",
    "def data_split(\n",
    "    features: pd.DataFrame, label: pd.Series, test_size: float\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Split 80% of data as a training set and the remaining 20% of the data as testing set\n",
    "    return training and testing sets in the following order: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        features, label, test_size=test_size)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7a7832",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@typechecked\n",
    "def train_ridge_regression(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    x_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    "    max_iter: int = int(1e8),\n",
    ") -> Dict[float, float]:\n",
    "    \"\"\"\n",
    "    Instantiate an object of Ridge Regression, train the model object using training data for the given `n'\n",
    "    iterations and in each iteration train the model for all lambda_vals as alpha and store roc scores of all lambda\n",
    "    values in all iterations in aucs dictionary\n",
    "\n",
    "    Rest of the provided handles the return part\n",
    "    \"\"\"\n",
    "    n = int(1e3)\n",
    "    aucs = {\"ridge\": []}\n",
    "    lambda_vals = [1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3]\n",
    "\n",
    "    for i in range(n):\n",
    "        for lambda_val in lambda_vals:\n",
    "            ridge = Ridge(alpha=lambda_val, max_iter=max_iter)\n",
    "            ridge.fit(x_train, y_train)\n",
    "            y_pred = ridge.predict(x_test)\n",
    "            auc = roc_auc_score(y_test, y_pred)\n",
    "            aucs[\"ridge\"].append(auc)\n",
    "\n",
    "    print(\"ridge mean AUCs:\")\n",
    "    ridge_aucs = pd.DataFrame(aucs[\"ridge\"])\n",
    "    ridge_mean_auc = {}\n",
    "    ridge_aucs = pd.DataFrame(aucs[\"ridge\"])\n",
    "    for lambda_val, ridge_auc in zip(lambda_vals, ridge_aucs.mean()):\n",
    "        ridge_mean_auc[lambda_val] = ridge_auc\n",
    "        print(\"lambda:\", lambda_val, \"AUC:\", \"%.4f\" % ridge_auc)\n",
    "    return ridge_mean_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3b6b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@typechecked\n",
    "def train_lasso(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    x_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    "    max_iter=int(1e8),\n",
    ") -> Dict[float, float]:\n",
    "    \"\"\"\n",
    "    Instantiate an object of Lasso Model, train the object using training data for the given `n'\n",
    "    iterations and in each iteration train the model for all lambda_vals as alpha and store roc scores of all lambda\n",
    "    values in all iterations in aucs dictionary\n",
    "\n",
    "    Rest of the provided handles the return part\n",
    "    \"\"\"\n",
    "    n = int(1e3)\n",
    "    aucs = {\"lasso\": []}\n",
    "    lambda_vals = [1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3]\n",
    "\n",
    "    for i in range(n):\n",
    "        for lambda_val in lambda_vals:\n",
    "            lasso = Lasso(alpha=lambda_val, max_iter=max_iter)\n",
    "            lasso.fit(x_train, y_train)\n",
    "            y_pred = lasso.predict(x_test)\n",
    "            aucs[\"ridge\"].append(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "    print(\"lasso mean AUCs:\")\n",
    "    lasso_mean_auc = {}\n",
    "    lasso_aucs = pd.DataFrame(aucs[\"lasso\"])\n",
    "    for lambda_val, lasso_auc in zip(lambda_vals, lasso_aucs.mean()):\n",
    "        lasso_mean_auc[lambda_val] = lasso_auc\n",
    "        print(\"lambda:\", lambda_val, \"AUC:\", \"%.4f\" % lasso_auc)\n",
    "    return lasso_mean_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb35e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@typechecked\n",
    "def ridge_coefficients(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    optimal_alpha: float,\n",
    "    max_iter=int(1e8),\n",
    ") -> Tuple[Ridge, np.ndarray]:\n",
    "    \"\"\"\n",
    "    return the tuple consisting of trained Ridge model with alpha as optimal_alpha and the coefficients\n",
    "    of the model\n",
    "    \"\"\"\n",
    "    ridge: Ridge = Ridge(alpha=optimal_alpha, max_iter=max_iter)\n",
    "    ridge.fit(x_train, y_train)\n",
    "    return ridge, ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0771a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@typechecked\n",
    "def lasso_coefficients(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    optimal_alpha: float,\n",
    "    max_iter=int(1e8),\n",
    ") -> Tuple[Lasso, np.ndarray]:\n",
    "    \"\"\"\n",
    "    return the tuple consisting of trained Lasso model with alpha as optimal_alpha and the coefficients\n",
    "    of the model\n",
    "    \"\"\"\n",
    "    lasso: Lasso = Lasso(alpha=optimal_alpha, max_iter=max_iter)\n",
    "    lasso.fit(x_train, y_train)\n",
    "    return lasso, lasso.ceof_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2944459",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@typechecked\n",
    "def ridge_area_under_curve(\n",
    "    model_R, x_test: pd.DataFrame, y_test: pd.Series\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    return area under the curve measurements of trained Ridge model used to find coefficients,\n",
    "    i.e., model tarined with optimal_aplha\n",
    "    Finally plot the ROC Curve using false_positive_rate, true_positive_rate as x and y axes calculated from roc_curve\n",
    "    \"\"\"\n",
    "    y_prob = model_R.predict_proba(x_test)[:, 1]\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dae2170",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@typechecked\n",
    "def lasso_area_under_curve(\n",
    "    model_L, x_test: pd.DataFrame, y_test: pd.Series\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    return area under the curve measurements of Lasso Model,\n",
    "    i.e., model tarined with optimal_aplha\n",
    "    Finally plot the ROC Curve using false_positive_rate, true_positive_rate as x and y axes calculated from roc_curve\n",
    "    \"\"\"\n",
    "    ########################\n",
    "    ## Your Solution Here ##\n",
    "    ########################\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c91a68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Node:\n",
    "    @typechecked\n",
    "    def __init__(\n",
    "        self,\n",
    "        split_val: float,\n",
    "        data: Any = None,\n",
    "        left: Any = None,\n",
    "        right: Any = None,\n",
    "    ) -> None:\n",
    "        if left is not None:\n",
    "            assert isinstance(left, Node)\n",
    "\n",
    "        if right is not None:\n",
    "            assert isinstance(right, Node)\n",
    "\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        # value (of a variable) on which to split. For leaf nodes this is label/output value\n",
    "        self.split_val = split_val\n",
    "        self.data = data  # data can be anything! we recommend dictionary with all variables you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d628af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TreeRegressor:\n",
    "    @typechecked\n",
    "    def __init__(self, data: np.ndarray, max_depth: int) -> None:\n",
    "        self.data = (\n",
    "            data  # last element of each row in data is the target variable\n",
    "        )\n",
    "        self.max_depth = max_depth  # maximum depth\n",
    "        # YOU MAY ADD ANY OTHER VARIABLES THAT YOU NEED HERE\n",
    "        # YOU MAY ALSO ADD FUNCTIONS **WITHIN CLASS or functions INSIDE CLASS** TO HELP YOU ORGANIZE YOUR BETTER\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "    @typechecked\n",
    "    def build_tree(self) -> Node:\n",
    "        \"\"\"\n",
    "        Build the tree\n",
    "        \"\"\"\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        pass\n",
    "\n",
    "    @typechecked\n",
    "    def mean_squared_error(\n",
    "        self, left_split: np.ndarray, right_split: np.ndarray\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Calculate the mean squared error for a split dataset\n",
    "        left split is a list of rows of a df, rightmost element is label\n",
    "        return the sum of mse of left split and right split\n",
    "        \"\"\"\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        pass\n",
    "\n",
    "    @typechecked\n",
    "    def split(self, node: Node, depth: int) -> None:\n",
    "        \"\"\"\n",
    "        Do the split operation recursively\n",
    "        \"\"\"\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        pass\n",
    "\n",
    "    @typechecked\n",
    "    def get_best_split(self, data: np.ndarray) -> Node:\n",
    "        \"\"\"\n",
    "        Select the best split point for a dataset AND create a Node\n",
    "        \"\"\"\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        pass\n",
    "\n",
    "    @typechecked\n",
    "    def one_step_split(\n",
    "        self, index: int, value: float, data: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Split a dataset based on an attribute and an attribute value\n",
    "        index is the variable to be split on (left split < threshold)\n",
    "        returns the left and right split each as list\n",
    "        each list has elements as `rows' of the df\n",
    "        \"\"\"\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50f5a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@typechecked\n",
    "def compare_node_with_threshold(node: Node, row: np.ndarray) -> bool:\n",
    "    \"\"\"\n",
    "    Return True if node's value > row's value (of the variable)\n",
    "    Else False\n",
    "    \"\"\"\n",
    "    ######################\n",
    "    ### YOUR CODE HERE ###\n",
    "    ######################\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3eaab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@typechecked\n",
    "def predict(\n",
    "    node: Node, row: np.ndarray, comparator: Callable[[Node, np.ndarray], bool]\n",
    ") -> float:\n",
    "    ######################\n",
    "    ### YOUR CODE HERE ###\n",
    "    ######################\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf14370",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TreeClassifier(TreeRegressor):\n",
    "    def build_tree(self):\n",
    "        # Note: You can remove this if you want to use build tree from Tree Regressor\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        pass\n",
    "\n",
    "    @typechecked\n",
    "    def gini_index(\n",
    "        self,\n",
    "        left_split: np.ndarray,\n",
    "        right_split: np.ndarray,\n",
    "        classes: List[float],\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Calculate the Gini index for a split dataset\n",
    "        Similar to MSE but Gini index instead\n",
    "        \"\"\"\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        pass\n",
    "\n",
    "    @typechecked\n",
    "    def get_best_split(self, data: np.ndarray) -> Node:\n",
    "        \"\"\"\n",
    "        Select the best split point for a dataset\n",
    "        \"\"\"\n",
    "        classes = list(set(row[-1] for row in data))\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cc7778",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Question 1\n",
    "    filename = \"./Hitters.csv\"  # Provide the path of the dataset\n",
    "    df = read_data(filename)\n",
    "    lambda_vals = [1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3]\n",
    "    max_iter = 1e8\n",
    "    final_features, final_label = data_preprocess(df)\n",
    "    x_train, x_test, y_train, y_test = data_split(\n",
    "        final_features, final_label, 0.2\n",
    "    )\n",
    "    ridge_mean_acu = train_ridge_regression(x_train, y_train, x_test, y_test)\n",
    "    lasso_mean_acu = train_lasso(x_train, y_train, x_test, y_test)\n",
    "    model_R, ridge_coeff = ridge_coefficients(x_train, y_train, 10)\n",
    "    model_L, lasso_coeff = lasso_coefficients(x_train, y_train, 0.1)\n",
    "    ridge_auc = ridge_area_under_curve(model_R, x_test, y_test)\n",
    "\n",
    "    # Plot the ROC curve of the Ridge Model. Include axes labels,\n",
    "    # legend and title in the Plot. Any of the missing\n",
    "    # items in plot will result in loss of points.\n",
    "    ########################\n",
    "    ## Your Solution Here ##\n",
    "    ########################\n",
    "\n",
    "    lasso_auc = lasso_area_under_curve(model_L, x_test, y_test)\n",
    "\n",
    "    # Plot the ROC curve of the Lasso Model.\n",
    "    # Include axes labels, legend and title in the Plot.\n",
    "    # Any of the missing items in plot will result in loss of points.\n",
    "    ########################\n",
    "    ## Your Solution Here ##\n",
    "    ########################\n",
    "\n",
    "    # SUB Q1\n",
    "    data_regress = np.loadtxt(csvname, delimiter=\",\")\n",
    "    data_regress = np.array([[x, y] for x, y in zip(*data_regress)])\n",
    "    plt.figure()\n",
    "    plt.scatter(data_regress[:, 0], data_regress[:, 1])\n",
    "    plt.xlabel(\"Features, x\")\n",
    "    plt.ylabel(\"Target values, y\")\n",
    "    plt.show()\n",
    "\n",
    "    mse_depths = []\n",
    "    for depth in range(1, 5):\n",
    "        regressor = TreeRegressor(data_regress, depth)\n",
    "        tree = regressor.build_tree()\n",
    "        mse = 0.0\n",
    "        for data_point in data_regress:\n",
    "            mse += (\n",
    "                data_point[1]\n",
    "                - predict(tree, data_point, compare_node_with_threshold)\n",
    "            ) ** 2\n",
    "        mse_depths.append(mse / len(data_regress))\n",
    "    plt.figure()\n",
    "    plt.plot(mse_depths)\n",
    "    plt.xlabel(\"Depth\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.show()\n",
    "\n",
    "    # SUB Q2\n",
    "    # Place the CSV file in the same directory as this notebook\n",
    "    csvname = \"new_circle_data.csv\"\n",
    "    data_class = np.loadtxt(csvname, delimiter=\",\")\n",
    "    data_class = np.array([[x1, x2, y] for x1, x2, y in zip(*data_class)])\n",
    "    plt.figure()\n",
    "    plt.scatter(\n",
    "        data_class[:, 0], data_class[:, 1], c=-data_class[:, 2], cmap=\"bwr\"\n",
    "    )\n",
    "    plt.xlabel(\"Features, x1\")\n",
    "    plt.ylabel(\"Features, x2\")\n",
    "    plt.show()\n",
    "\n",
    "    accuracy_depths = []\n",
    "    for depth in range(1, 8):\n",
    "        classifier = TreeClassifier(data_class, depth)\n",
    "        tree = classifier.build_tree()\n",
    "        correct = 0.0\n",
    "        for data_point in data_class:\n",
    "            correct += float(\n",
    "                data_point[2]\n",
    "                == predict(tree, data_point, compare_node_with_threshold)\n",
    "            )\n",
    "        accuracy_depths.append(correct / len(data_class))\n",
    "    # Plot the MSE\n",
    "    plt.figure()\n",
    "    plt.plot(accuracy_depths)\n",
    "    plt.xlabel(\"Depth\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
