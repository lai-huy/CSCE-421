{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "979a697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from typing import Tuple, List, Optional, Any, Callable, Dict, Union\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import random\n",
    "from typeguard import typechecked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcd64af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe623708",
   "metadata": {},
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def read_data(filename: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read the data from the filename. Load the data it in a dataframe and return it.\n",
    "    \"\"\"\n",
    "    data: pd.DataFrame = pd.read_csv(filename)\n",
    "    data = data.dropna()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9ddeac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def data_preprocess(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Follow all the preprocessing steps mentioned in Problem 2 of HW2 (Problem 2: Coding: Preprocessing the Data.)\n",
    "    Return the final features and final label in same order\n",
    "    You may use the same code you submiited for problem 2 of HW2\n",
    "    \"\"\"\n",
    "    df_numerical: pd.DataFrame = df.select_dtypes(include=['int64', 'float64'])\n",
    "    df_categorical: pd.DataFrame = df.select_dtypes(exclude=['int64', 'float64'])\n",
    "    df_categorical = pd.get_dummies(df_categorical)\n",
    "\n",
    "    return pd.concat([df_categorical, df_numerical], axis=1), pd.Series(df['NewLeague'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9330300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def data_split(\n",
    "    features: pd.DataFrame, label: pd.Series, test_size: float\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Split 80% of data as a training set and the remaining 20% of the data as testing set\n",
    "    return training and testing sets in the following order: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, label, test_size=test_size)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d8cb4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def train_ridge_regression(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    x_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    "    max_iter: int = int(1e8),\n",
    ") -> Dict[float, float]:\n",
    "    \"\"\"\n",
    "    Instantiate an object of Ridge Regression, train the model object using training data for the given `n'\n",
    "    iterations and in each iteration train the model for all lambda_vals as alpha and store roc scores of all lambda\n",
    "    values in all iterations in aucs dictionary\n",
    "\n",
    "    Rest of the provided handles the return part\n",
    "    \"\"\"\n",
    "    n = int(1e3)\n",
    "    aucs = {\"ridge\": []}\n",
    "    lambda_vals = [1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3]\n",
    "\n",
    "    for i in range(n):\n",
    "        for lambda_val in lambda_vals:\n",
    "            ridge = Ridge(alpha=lambda_val, max_iter=max_iter)\n",
    "            ridge.fit(x_train, y_train)\n",
    "            y_pred = ridge.predict(x_test)\n",
    "            auc = roc_auc_score(y_test, y_pred)\n",
    "            aucs[\"ridge\"].append(auc)\n",
    "\n",
    "    print(\"ridge mean AUCs:\")\n",
    "    ridge_aucs = pd.DataFrame(aucs[\"ridge\"])\n",
    "    ridge_mean_auc = {}\n",
    "    ridge_aucs = pd.DataFrame(aucs[\"ridge\"])\n",
    "    for lambda_val, ridge_auc in zip(lambda_vals, ridge_aucs.mean()):\n",
    "        ridge_mean_auc[lambda_val] = ridge_auc\n",
    "        print(\"lambda:\", lambda_val, \"AUC:\", \"%.4f\" % ridge_auc)\n",
    "    return ridge_mean_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cadb83ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def train_lasso(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    x_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    "    max_iter=int(1e8),\n",
    ") -> Dict[float, float]:\n",
    "    \"\"\"\n",
    "    Instantiate an object of Lasso Model, train the object using training data for the given `n'\n",
    "    iterations and in each iteration train the model for all lambda_vals as alpha and store roc scores of all lambda\n",
    "    values in all iterations in aucs dictionary\n",
    "\n",
    "    Rest of the provided handles the return part\n",
    "    \"\"\"\n",
    "    n = int(1e3)\n",
    "    aucs = {\"lasso\": []}\n",
    "    lambda_vals = [1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3]\n",
    "\n",
    "    for i in range(n):\n",
    "        for lambda_val in lambda_vals:\n",
    "            lasso = Lasso(alpha=lambda_val, max_iter=max_iter)\n",
    "            lasso.fit(x_train, y_train)\n",
    "            y_pred = lasso.predict(x_test)\n",
    "            aucs[\"ridge\"].append(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "    print(\"lasso mean AUCs:\")\n",
    "    lasso_mean_auc = {}\n",
    "    lasso_aucs = pd.DataFrame(aucs[\"lasso\"])\n",
    "    for lambda_val, lasso_auc in zip(lambda_vals, lasso_aucs.mean()):\n",
    "        lasso_mean_auc[lambda_val] = lasso_auc\n",
    "        print(\"lambda:\", lambda_val, \"AUC:\", \"%.4f\" % lasso_auc)\n",
    "    return lasso_mean_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "507a0cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def ridge_coefficients(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    optimal_alpha: float,\n",
    "    max_iter=int(1e8),\n",
    ") -> Tuple[Ridge, np.ndarray]:\n",
    "    \"\"\"\n",
    "    return the tuple consisting of trained Ridge model with alpha as optimal_alpha and the coefficients\n",
    "    of the model\n",
    "    \"\"\"\n",
    "    ridge: Ridge = Ridge(alpha=optimal_alpha, max_iter=max_iter)\n",
    "    ridge.fit(x_train, y_train)\n",
    "    return ridge, ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d331448",
   "metadata": {},
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def lasso_coefficients(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    optimal_alpha: float,\n",
    "    max_iter=int(1e8),\n",
    ") -> Tuple[Lasso, np.ndarray]:\n",
    "    \"\"\"\n",
    "    return the tuple consisting of trained Lasso model with alpha as optimal_alpha and the coefficients\n",
    "    of the model\n",
    "    \"\"\"\n",
    "    lasso: Lasso = Lasso(alpha=optimal_alpha, max_iter=max_iter)\n",
    "    lasso.fit(x_train, y_train)\n",
    "    return lasso, lasso.ceof_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cf65b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def ridge_area_under_curve(\n",
    "    model_R, x_test: pd.DataFrame, y_test: pd.Series\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    return area under the curve measurements of trained Ridge model used to find coefficients,\n",
    "    i.e., model tarined with optimal_aplha\n",
    "    Finally plot the ROC Curve using false_positive_rate, true_positive_rate as x and y axes calculated from roc_curve\n",
    "    \"\"\"\n",
    "    y_prob = model_R.predict_proba(x_test)[:, 1]\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2042f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def lasso_area_under_curve(\n",
    "    model_L, x_test: pd.DataFrame, y_test: pd.Series\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    return area under the curve measurements of Lasso Model,\n",
    "    i.e., model tarined with optimal_aplha\n",
    "    Finally plot the ROC Curve using false_positive_rate, true_positive_rate as x and y axes calculated from roc_curve\n",
    "    \"\"\"\n",
    "    ########################\n",
    "    ## Your Solution Here ##\n",
    "    ########################\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5907946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    @typechecked\n",
    "    def __init__(\n",
    "        self,\n",
    "        split_val: float,\n",
    "        data: Any = None,\n",
    "        left: Any = None,\n",
    "        right: Any = None,\n",
    "    ) -> None:\n",
    "        if left is not None:\n",
    "            assert isinstance(left, Node)\n",
    "\n",
    "        if right is not None:\n",
    "            assert isinstance(right, Node)\n",
    "\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        # value (of a variable) on which to split. For leaf nodes this is label/output value\n",
    "        self.split_val = split_val\n",
    "        self.data = data  # data can be anything! we recommend dictionary with all variables you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b67ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeRegressor:\n",
    "    @typechecked\n",
    "    def __init__(self, data: np.ndarray, max_depth: int) -> None:\n",
    "        self.data = (\n",
    "            data  # last element of each row in data is the target variable\n",
    "        )\n",
    "        self.max_depth = max_depth  # maximum depth\n",
    "        # YOU MAY ADD ANY OTHER VARIABLES THAT YOU NEED HERE\n",
    "        # YOU MAY ALSO ADD FUNCTIONS **WITHIN CLASS or functions INSIDE CLASS** TO HELP YOU ORGANIZE YOUR BETTER\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "    @typechecked\n",
    "    def build_tree(self) -> Node:\n",
    "        \"\"\"\n",
    "        Build the tree\n",
    "        \"\"\"\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        pass\n",
    "\n",
    "    @typechecked\n",
    "    def mean_squared_error(\n",
    "        self, left_split: np.ndarray, right_split: np.ndarray\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Calculate the mean squared error for a split dataset\n",
    "        left split is a list of rows of a df, rightmost element is label\n",
    "        return the sum of mse of left split and right split\n",
    "        \"\"\"\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        pass\n",
    "\n",
    "    @typechecked\n",
    "    def split(self, node: Node, depth: int) -> None:\n",
    "        \"\"\"\n",
    "        Do the split operation recursively\n",
    "        \"\"\"\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        pass\n",
    "\n",
    "    @typechecked\n",
    "    def get_best_split(self, data: np.ndarray) -> Node:\n",
    "        \"\"\"\n",
    "        Select the best split point for a dataset AND create a Node\n",
    "        \"\"\"\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        pass\n",
    "\n",
    "    @typechecked\n",
    "    def one_step_split(\n",
    "        self, index: int, value: float, data: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Split a dataset based on an attribute and an attribute value\n",
    "        index is the variable to be split on (left split < threshold)\n",
    "        returns the left and right split each as list\n",
    "        each list has elements as `rows' of the df\n",
    "        \"\"\"\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b378a709",
   "metadata": {},
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def compare_node_with_threshold(node: Node, row: np.ndarray) -> bool:\n",
    "    \"\"\"\n",
    "    Return True if node's value > row's value (of the variable)\n",
    "    Else False\n",
    "    \"\"\"\n",
    "    ######################\n",
    "    ### YOUR CODE HERE ###\n",
    "    ######################\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1a4872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def predict(\n",
    "    node: Node, row: np.ndarray, comparator: Callable[[Node, np.ndarray], bool]\n",
    ") -> float:\n",
    "    ######################\n",
    "    ### YOUR CODE HERE ###\n",
    "    ######################\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "371c26d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeClassifier(TreeRegressor):\n",
    "    def build_tree(self):\n",
    "        # Note: You can remove this if you want to use build tree from Tree Regressor\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        pass\n",
    "\n",
    "    @typechecked\n",
    "    def gini_index(\n",
    "        self,\n",
    "        left_split: np.ndarray,\n",
    "        right_split: np.ndarray,\n",
    "        classes: List[float],\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Calculate the Gini index for a split dataset\n",
    "        Similar to MSE but Gini index instead\n",
    "        \"\"\"\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        pass\n",
    "\n",
    "    @typechecked\n",
    "    def get_best_split(self, data: np.ndarray) -> Node:\n",
    "        \"\"\"\n",
    "        Select the best split point for a dataset\n",
    "        \"\"\"\n",
    "        classes = list(set(row[-1] for row in data))\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af5cfab8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'A'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m final_features, final_label \u001b[39m=\u001b[39m data_preprocess(df)\n\u001b[1;32m      8\u001b[0m x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m data_split(\n\u001b[1;32m      9\u001b[0m     final_features, final_label, \u001b[39m0.2\u001b[39m\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m ridge_mean_acu \u001b[39m=\u001b[39m train_ridge_regression(x_train, y_train, x_test, y_test)\n\u001b[1;32m     12\u001b[0m lasso_mean_acu \u001b[39m=\u001b[39m train_lasso(x_train, y_train, x_test, y_test)\n\u001b[1;32m     13\u001b[0m model_R, ridge_coeff \u001b[39m=\u001b[39m ridge_coefficients(x_train, y_train, \u001b[39m10\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/typeguard/__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m memo \u001b[39m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[0;32m-> 1033\u001b[0m retval \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "Cell \u001b[0;32mIn[6], line 23\u001b[0m, in \u001b[0;36mtrain_ridge_regression\u001b[0;34m(x_train, y_train, x_test, y_test, max_iter)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m lambda_val \u001b[39min\u001b[39;00m lambda_vals:\n\u001b[1;32m     22\u001b[0m     ridge \u001b[39m=\u001b[39m Ridge(alpha\u001b[39m=\u001b[39mlambda_val, max_iter\u001b[39m=\u001b[39mmax_iter)\n\u001b[0;32m---> 23\u001b[0m     ridge\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n\u001b[1;32m     24\u001b[0m     y_pred \u001b[39m=\u001b[39m ridge\u001b[39m.\u001b[39mpredict(x_test)\n\u001b[1;32m     25\u001b[0m     auc \u001b[39m=\u001b[39m roc_auc_score(y_test, y_pred)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:1126\u001b[0m, in \u001b[0;36mRidge.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1125\u001b[0m _accept_sparse \u001b[39m=\u001b[39m _get_valid_accept_sparse(sparse\u001b[39m.\u001b[39missparse(X), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msolver)\n\u001b[0;32m-> 1126\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   1127\u001b[0m     X,\n\u001b[1;32m   1128\u001b[0m     y,\n\u001b[1;32m   1129\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m_accept_sparse,\n\u001b[1;32m   1130\u001b[0m     dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32],\n\u001b[1;32m   1131\u001b[0m     multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1132\u001b[0m     y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1133\u001b[0m )\n\u001b[1;32m   1134\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    564\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 565\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1122\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1107\u001b[0m     X,\n\u001b[1;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1120\u001b[0m )\n\u001b[0;32m-> 1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39;49mmulti_output, y_numeric\u001b[39m=\u001b[39;49my_numeric, estimator\u001b[39m=\u001b[39;49mestimator)\n\u001b[1;32m   1124\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1126\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1147\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     _ensure_no_complex_data(y)\n\u001b[1;32m   1146\u001b[0m \u001b[39mif\u001b[39;00m y_numeric \u001b[39mand\u001b[39;00m y\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mO\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 1147\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat64)\n\u001b[1;32m   1149\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'A'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Question 1\n",
    "    filename = \"./Hitters.csv\"  # Provide the path of the dataset\n",
    "    df = read_data(filename)\n",
    "    lambda_vals = [1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3]\n",
    "    max_iter = 1e8\n",
    "    final_features, final_label = data_preprocess(df)\n",
    "    x_train, x_test, y_train, y_test = data_split(\n",
    "        final_features, final_label, 0.2\n",
    "    )\n",
    "    ridge_mean_acu = train_ridge_regression(x_train, y_train, x_test, y_test)\n",
    "    lasso_mean_acu = train_lasso(x_train, y_train, x_test, y_test)\n",
    "    model_R, ridge_coeff = ridge_coefficients(x_train, y_train, 10)\n",
    "    model_L, lasso_coeff = lasso_coefficients(x_train, y_train, 0.1)\n",
    "    ridge_auc = ridge_area_under_curve(model_R, x_test, y_test)\n",
    "\n",
    "    # Plot the ROC curve of the Ridge Model. Include axes labels,\n",
    "    # legend and title in the Plot. Any of the missing\n",
    "    # items in plot will result in loss of points.\n",
    "    ########################\n",
    "    ## Your Solution Here ##\n",
    "    ########################\n",
    "\n",
    "    lasso_auc = lasso_area_under_curve(model_L, x_test, y_test)\n",
    "\n",
    "    # Plot the ROC curve of the Lasso Model.\n",
    "    # Include axes labels, legend and title in the Plot.\n",
    "    # Any of the missing items in plot will result in loss of points.\n",
    "    ########################\n",
    "    ## Your Solution Here ##\n",
    "    ########################\n",
    "\n",
    "    # SUB Q1\n",
    "    data_regress = np.loadtxt(csvname, delimiter=\",\")\n",
    "    data_regress = np.array([[x, y] for x, y in zip(*data_regress)])\n",
    "    plt.figure()\n",
    "    plt.scatter(data_regress[:, 0], data_regress[:, 1])\n",
    "    plt.xlabel(\"Features, x\")\n",
    "    plt.ylabel(\"Target values, y\")\n",
    "    plt.show()\n",
    "\n",
    "    mse_depths = []\n",
    "    for depth in range(1, 5):\n",
    "        regressor = TreeRegressor(data_regress, depth)\n",
    "        tree = regressor.build_tree()\n",
    "        mse = 0.0\n",
    "        for data_point in data_regress:\n",
    "            mse += (\n",
    "                data_point[1]\n",
    "                - predict(tree, data_point, compare_node_with_threshold)\n",
    "            ) ** 2\n",
    "        mse_depths.append(mse / len(data_regress))\n",
    "    plt.figure()\n",
    "    plt.plot(mse_depths)\n",
    "    plt.xlabel(\"Depth\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.show()\n",
    "\n",
    "    # SUB Q2\n",
    "    # Place the CSV file in the same directory as this notebook\n",
    "    csvname = \"new_circle_data.csv\"\n",
    "    data_class = np.loadtxt(csvname, delimiter=\",\")\n",
    "    data_class = np.array([[x1, x2, y] for x1, x2, y in zip(*data_class)])\n",
    "    plt.figure()\n",
    "    plt.scatter(\n",
    "        data_class[:, 0], data_class[:, 1], c=-data_class[:, 2], cmap=\"bwr\"\n",
    "    )\n",
    "    plt.xlabel(\"Features, x1\")\n",
    "    plt.ylabel(\"Features, x2\")\n",
    "    plt.show()\n",
    "\n",
    "    accuracy_depths = []\n",
    "    for depth in range(1, 8):\n",
    "        classifier = TreeClassifier(data_class, depth)\n",
    "        tree = classifier.build_tree()\n",
    "        correct = 0.0\n",
    "        for data_point in data_class:\n",
    "            correct += float(\n",
    "                data_point[2]\n",
    "                == predict(tree, data_point, compare_node_with_threshold)\n",
    "            )\n",
    "        accuracy_depths.append(correct / len(data_class))\n",
    "    # Plot the MSE\n",
    "    plt.figure()\n",
    "    plt.plot(accuracy_depths)\n",
    "    plt.xlabel(\"Depth\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8a94588eda9d64d9e9a351ab8144e55b1fabf5113b54e67dd26a8c27df0381b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
