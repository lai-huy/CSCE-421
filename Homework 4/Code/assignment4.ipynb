{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf8b8cbb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from typeguard import typechecked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79097285",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd4362",
   "metadata": {},
   "source": [
    "###############\n",
    "###############\n",
    "# Q1\n",
    "###############\n",
    "###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbc3bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "@typechecked\n",
    "def read_classification_data(file_path: str) -> Tuple[np.array, np.array]:\n",
    "    '''\n",
    "\t\tRead the data from the path.\n",
    "\t\tReturn the data as 2 np arrays each with shape (number_of_rows_in_dataframe, 1)\n",
    "\t\tOrder (np.array from first row), (np.array from second row)\n",
    "    '''\n",
    "    df: pd.DataFrame = pd.read_csv(file_path, header=None)\n",
    "    X: np.ndarray = df.iloc[:, 0].to_numpy().reshape(-1, 1)\n",
    "    y: np.ndarray = df.iloc[:, 1].to_numpy().reshape(-1, 1)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "539b99f6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def sigmoid(s: np.array) -> np.array:\n",
    "    '''\n",
    "      Return the sigmoid of every number in the array s as an array of floating point numbers\n",
    "      sigmoid(s)= 1/(1+e^(-s))\n",
    "    '''\n",
    "    return 1 / (1 + np.exp(-s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c948f55",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def cost_function(w: float, b: float, X: np.array, y: np.array) -> float:\n",
    "    '''\n",
    "\t\tInputs definitions:\n",
    "\t\t\tw : weight\n",
    "\t\t\tb : bias\n",
    "\t\t\tX : input  with shape (number_of_rows_in_dataframe, 1)\n",
    "\t\t\ty : target with shape (number_of_rows_in_dataframe, 1)\n",
    "\t\tReturn the loss as a float data type. \n",
    "    '''\n",
    "    n = len(y)\n",
    "    y_pred = sigmoid(np.dot(X, w) + b)\n",
    "    loss = -np.sum(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred)) / n\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ed2f58d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def cross_entropy_optimizer(w: float, b: float, X: np.array, y: np.array, num_iterations: int, alpha: float) -> Tuple[float, float, list]:\n",
    "    '''\n",
    "        Inputs definitions:\n",
    "            w              : initial weight\n",
    "            b              : initial bias\n",
    "            X              : input  with shape (number_of_rows_in_dataframe, 1)\n",
    "            y              : target with shape (number_of_rows_in_dataframe, 1)\n",
    "            num_iterations : number of iterations \n",
    "            alpha          : Learning rate\n",
    "\n",
    "        Task: Iterate for given number of iterations and find optimal weight and bias \n",
    "        while also noting the change in cost/ loss after every iteration\n",
    "\n",
    "        Make use of the cost_function() above\n",
    "\n",
    "        Return (updated weight, updated bias, list of \"costs\" after each iteration) in this order\n",
    "        \"costs\" list contains float type numbers  \n",
    "    '''\n",
    "    costs = []\n",
    "    for i in range(num_iterations):\n",
    "        y_pred = sigmoid(np.dot(X, w) + b)\n",
    "        dw: float = np.dot(X.T, (y_pred - y)) / len(y)\n",
    "        db: float = np.sum(y_pred - y) / len(y)\n",
    "        w -= alpha * dw\n",
    "        b -= alpha * db\n",
    "        cost = cost_function(w, b, X, y)\n",
    "        costs.append(cost)\n",
    "    return w, b, costs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c588ccdb",
   "metadata": {},
   "source": [
    "###############\n",
    "###############\n",
    "# Q3 a\n",
    "###############\n",
    "###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61d08376",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def read_sat_image_data(file_path: str) -> pd.DataFrame:\n",
    "    '''\n",
    "\t\tInput: filepath to a .csv file\n",
    "\t\tOutput: Return a DataFrame with the data from the given csv file \n",
    "    '''\n",
    "    return pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbc84a6f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def remove_nan(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    \tRemove nan values from the dataframe and return it\n",
    "    '''\n",
    "    return df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c55c8e35",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def normalize_data(Xtrain: pd.DataFrame, Xtest: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "\t'''\n",
    "\t\tNormalize each column of the dataframes and Return the dataframes\n",
    "\t\tUse sklearn.preprocessing.StandardScaler library to normalize\n",
    "\t\tReturn the results in the order Xtrain_norm, Xtest_norm\n",
    "\t'''\n",
    "\tscaler = StandardScaler()\n",
    "\tXtrain_norm = pd.DataFrame(scaler.fit_transform(Xtrain), columns=Xtrain.columns)\n",
    "\tXtest_norm = pd.DataFrame(scaler.transform(Xtest), columns=Xtest.columns)\n",
    "\treturn Xtrain_norm, Xtest_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60c838b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def labels_to_binary(y: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Make the lables [1,2,3,4,5] as 0 and [6] as 1\n",
    "    Return the DataFrame \n",
    "    '''\n",
    "    ########################\n",
    "    ## Your Solution Here ##\n",
    "    ########################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30616668",
   "metadata": {},
   "source": [
    "###############\n",
    "###############\n",
    "# Q3 b\n",
    "###############\n",
    "###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f865c4e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def cross_validate_c_vals(X: pd.DataFrame, y: pd.DataFrame, n_folds: int, c_vals: np.array, d_vals: np.array) -> (np.array, np.array):\n",
    "    '''\n",
    "      Return the matrices (ERRAVGdc, ERRSTDdc) in the same order\n",
    "      More details about the imlementation are provided in the main function\n",
    "    '''\n",
    "    ########################\n",
    "    ## Your Solution Here ##\n",
    "    ########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea14a6b6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def plot_cross_val_err_vs_c(ERRAVGdc: np.array, ERRSTDdc: np.array, c_vals: np.array, d_vals: np.array) -> None:\n",
    "    '''\n",
    "     Please write the code in below block to generate the graphs as described in the question.\n",
    "     Note that the code will not be graded, but the graphs submitted in the report will be evaluated.\n",
    "    '''\n",
    "    ########################\n",
    "    ## Your Solution Here ##\n",
    "    ########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1edb2287",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "################\n",
    "################\n",
    "# Q3 c\n",
    "################\n",
    "################\n",
    "@typechecked\n",
    "def evaluate_c_d_pairs(X_train: pd.DataFrame, y_train: pd.DataFrame, X_test: pd.DataFrame, y_test: pd.DataFrame, n_folds: int, c_vals: np.array, d_vals: np.array) -> Tuple[np.array, np.array, np.array, np.array]:\n",
    "    '''\n",
    "      Return in the order: ERRAVGdcTEST, SuppVect, vmd, MarginT\n",
    "      More details about the imlementation are provided in the main function\n",
    "      Shape:\n",
    "        ERRAVGdcTEST = np array with shape len(d_vals)\n",
    "        SuppVect     = np array with shape len(d_vals)\n",
    "        vmd          = np array with shape len(d_vals)\n",
    "        MarginT      = np array with shape len(d_vals)\n",
    "    '''\n",
    "    ########################\n",
    "    ## Your Solution Here ##\n",
    "    ########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b774f69",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def plot_test_errors(ERRAVGdcTEST: np.array, d_vals: np.array) -> None:\n",
    "    '''\n",
    "     Please write the code in below block to generate the graphs as described in the question.\n",
    "     Note that the code will not be graded, but the graphs submitted in the report will be evaluated.\n",
    "    '''\n",
    "    ########################\n",
    "    ## Your Solution Here ##\n",
    "    ########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "698bc8f9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "################\n",
    "################\n",
    "# Q3 d\n",
    "################\n",
    "################\n",
    "@typechecked\n",
    "def plot_avg_support_vec(SuppVect: np.array, d_vals: np.array) -> None:\n",
    "    '''\n",
    "     Please write the code in below block to generate the graphs as described in the question.\n",
    "     Note that the code will not be graded, but the graphs submitted in the report will be evaluated.\n",
    "    '''\n",
    "    ########################\n",
    "    ## Your Solution Here ##\n",
    "    ########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a2da1be",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@typechecked\n",
    "def plot_avg_violating_support_vec(vmd: np.array, d_vals: np.array) -> None:\n",
    "    '''\n",
    "     Please write the code in below block to generate the graphs as described in the question.\n",
    "     Note that the code will not be graded, but the graphs submitted in the report will be evaluated.\n",
    "    '''\n",
    "    ########################\n",
    "    ## Your Solution Here ##\n",
    "    ########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66f5323f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "################\n",
    "################\n",
    "# Q3 e\n",
    "################\n",
    "################\n",
    "@typechecked\n",
    "def plot_avg_hyperplane_margins(MarginT: np.array, d_vals: np.array) -> None:\n",
    "    '''\n",
    "     Please write the code in below block to generate the graphs as described in the question.\n",
    "     Note that the code will not be graded, but the graphs submitted in the report will be evaluated.\n",
    "    '''\n",
    "    ########################\n",
    "    ## Your Solution Here ##\n",
    "    ########################\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7688bac0",
   "metadata": {},
   "source": [
    "# General Instructions\n",
    "If you want to use a library which is not already included at the top of this file,\n",
    "import them in the function in which you are using the library, not at the top of this file.\n",
    "If you import it at the top of this file, your code will not be evaluated correctly by the autograder.\n",
    "You will not be awarded any points if your code fails because of this reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fad1f59b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "type of argument \"w\" must be either float or int; got numpy.ndarray instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m b: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     24\u001b[0m num_iterations: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m300\u001b[39m\n\u001b[0;32m---> 25\u001b[0m w, b, costs \u001b[39m=\u001b[39m cross_entropy_optimizer(w, b, x, y, num_iterations, \u001b[39m0.1\u001b[39;49m)\n\u001b[1;32m     26\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWeignt W: \u001b[39m\u001b[39m\"\u001b[39m, w)\n\u001b[1;32m     27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBias b: \u001b[39m\u001b[39m\"\u001b[39m, b)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/typeguard/__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m memo \u001b[39m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[0;32m-> 1033\u001b[0m retval \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "Cell \u001b[0;32mIn[24], line 27\u001b[0m, in \u001b[0;36mcross_entropy_optimizer\u001b[0;34m(w, b, X, y, num_iterations, alpha)\u001b[0m\n\u001b[1;32m     25\u001b[0m     w \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m alpha \u001b[39m*\u001b[39m dw\n\u001b[1;32m     26\u001b[0m     b \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m alpha \u001b[39m*\u001b[39m db\n\u001b[0;32m---> 27\u001b[0m     cost \u001b[39m=\u001b[39m cost_function(w, b, X, y)\n\u001b[1;32m     28\u001b[0m     costs\u001b[39m.\u001b[39mappend(cost)\n\u001b[1;32m     29\u001b[0m \u001b[39mreturn\u001b[39;00m w, b, costs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/typeguard/__init__.py:1032\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1031\u001b[0m     memo \u001b[39m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m-> 1032\u001b[0m     check_argument_types(memo)\n\u001b[1;32m   1033\u001b[0m     retval \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1034\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/typeguard/__init__.py:875\u001b[0m, in \u001b[0;36mcheck_argument_types\u001b[0;34m(memo)\u001b[0m\n\u001b[1;32m    873\u001b[0m             check_type(description, value, expected_type, memo)\n\u001b[1;32m    874\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:  \u001b[39m# suppress unnecessarily long tracebacks\u001b[39;00m\n\u001b[0;32m--> 875\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m*\u001b[39mexc\u001b[39m.\u001b[39margs) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    877\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: type of argument \"w\" must be either float or int; got numpy.ndarray instead"
     ]
    }
   ],
   "source": [
    "################\n",
    "################\n",
    "# Q1\n",
    "################\n",
    "################\n",
    "\n",
    "'''\n",
    "\tBelow we load the data.\n",
    "\tProvide the path for data.\n",
    "\tImplement- read_classification_data()\n",
    "'''\n",
    "classification_data_2d_path = \"./2d_classification_data_entropy.csv\"\n",
    "x, y = read_classification_data(classification_data_2d_path)\n",
    "\n",
    "'''\n",
    "    Below code initializes the weight and bias to 1, then iterates 300 times to find a better fit. \n",
    "    The cost/error is plotted against the number of iterations. \n",
    "    Please submit a screenshot of the plot in the report to receive points. \n",
    "    Implement- sigmoid(), cost_function(), cross_entropy_optimizer()\n",
    "'''\n",
    "\n",
    "w: float = 1\n",
    "b: float = 1\n",
    "num_iterations: int = 300\n",
    "w, b, costs = cross_entropy_optimizer(w, b, x, y, num_iterations, 0.1)\n",
    "print(\"Weignt W: \", w)\n",
    "print(\"Bias b: \", b)\n",
    "plt.plot(range(num_iterations), costs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "948b2200",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "type of the return value must be pandas.core.frame.DataFrame; got NoneType instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 39\u001b[0m\n\u001b[1;32m     35\u001b[0m Xtest \u001b[39m=\u001b[39m test_df_nan_removed\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mClass\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     37\u001b[0m Xtrain_norm, Xtest_norm \u001b[39m=\u001b[39m normalize_data(Xtrain, Xtest)\n\u001b[0;32m---> 39\u001b[0m ytrain_bin_label \u001b[39m=\u001b[39m labels_to_binary(ytrain)\n\u001b[1;32m     40\u001b[0m ytest_bin_label \u001b[39m=\u001b[39m labels_to_binary(ytest)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/typeguard/__init__.py:1037\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m     check_return_type(retval, memo)\n\u001b[1;32m   1036\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m-> 1037\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m*\u001b[39mexc\u001b[39m.\u001b[39margs) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m   1039\u001b[0m \u001b[39m# If a generator is returned, wrap it if its yield/send/return types can be checked\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[39mif\u001b[39;00m inspect\u001b[39m.\u001b[39misgenerator(retval) \u001b[39mor\u001b[39;00m isasyncgen(retval):\n",
      "\u001b[0;31mTypeError\u001b[0m: type of the return value must be pandas.core.frame.DataFrame; got NoneType instead"
     ]
    }
   ],
   "source": [
    "################\n",
    "################\n",
    "# Q3 a\n",
    "################\n",
    "################\n",
    "\n",
    "########################\n",
    "'''\n",
    "Below we load the data into dataframe.\n",
    "Provide the path for training and test data.\n",
    "Implement- read_sat_image_data()\n",
    "'''\n",
    "\n",
    "sat_image_Training_path = \"./satimageTraining.csv\"\n",
    "sat_image_Test_path = \"./satimageTest.csv\"\n",
    "\n",
    "train_df = read_sat_image_data(sat_image_Training_path)  # Training set\n",
    "test_df = read_sat_image_data(sat_image_Test_path)  # Testing set\n",
    "\n",
    "'''\n",
    "Below code \n",
    "-removes nan values from data frame\n",
    "-loads the train and test dataframes\n",
    "-Normalize the input dataframes\n",
    "-convert labels to binary\n",
    "Implement- remove_nan(), normalize_data(), labels_to_binary()\n",
    "'''\n",
    "train_df_nan_removed = remove_nan(train_df)\n",
    "test_df_nan_removed = remove_nan(test_df)\n",
    "\n",
    "ytrain = train_df_nan_removed[['Class']]\n",
    "Xtrain = train_df_nan_removed.drop(['Class'], axis=1)\n",
    "\n",
    "ytest = test_df_nan_removed[['Class']]\n",
    "Xtest = test_df_nan_removed.drop(['Class'], axis=1)\n",
    "\n",
    "Xtrain_norm, Xtest_norm = normalize_data(Xtrain, Xtest)\n",
    "\n",
    "ytrain_bin_label = labels_to_binary(ytrain)\n",
    "ytest_bin_label = labels_to_binary(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6874a920",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ytrain_bin_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m n_folds \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m     32\u001b[0m d_vals \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m])\n\u001b[1;32m     34\u001b[0m ERRAVGdc, ERRSTDdc \u001b[39m=\u001b[39m cross_validate_c_vals(\n\u001b[0;32m---> 35\u001b[0m \tXtrain_norm, ytrain_bin_label, n_folds, c_vals, d_vals)\n\u001b[1;32m     37\u001b[0m plot_cross_val_err_vs_c(ERRAVGdc, ERRSTDdc, c_vals, d_vals)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ytrain_bin_label' is not defined"
     ]
    }
   ],
   "source": [
    "################\n",
    "################\n",
    "# Q3 b\n",
    "################\n",
    "################\n",
    "'''\n",
    "ERRAVGdc is a matrix with ERRAVGdc[c][d] = \"Average Mean Absolute Error\" of 10 folds for 'C'=c and degree='d'\n",
    "ERRSTDdc is a matrix with ERRSTDdc[c][d] = \"Standard Deviation\" of 10 folds for 'C'=c and degree='d'\n",
    "Both the matrices have size (len(c_vals), len(d_vals))\n",
    "Fill these matrices in the cross_validate_c_vals function\n",
    "For each 'c' and 'd' values :\n",
    "Split the data into 10 folds and for each fold:\n",
    "\tFind the predictions and corresponding mean Absolute errors and store the error\n",
    "Evaluate the \"Average Mean Absolute Error\" and \"Standard Deviation\" from stored errors\n",
    "Update the ERRAVGdc[c][d], ERRSTDdc[c][d] with the evaluated \"Average Mean Absolute Error\" and \"Standard Deviation\"\n",
    "\t\n",
    "Note: 'C' is the trade-off constant, which controls the trade-off between a smooth decision boundary and classifying the training points correctly.\n",
    "Note: 'degree' is the degree of the polynomial kernel used with the SVM\n",
    "Matrices ERRAVGdc, ERRSTDdc look like this:\n",
    "\t\td=1   d=2   d=3   d=4\n",
    "--------- ---   ---   ---   --- \n",
    "c=0.01 | .     .     .     .\n",
    "c=0.1  | .     .     .     .\n",
    "c=1    | .     .     .     .\n",
    "c=10   | .     .     .     .\n",
    "c=100  | .     .     .     .\n",
    "\n",
    "Implement- cross_validate_c_vals(), plot_cross_val_err_vs_c()\n",
    "'''\n",
    "c_vals = np.power(float(10), range(-2, 2 + 1))\n",
    "n_folds = 5\n",
    "d_vals = np.array([1, 2, 3, 4])\n",
    "\n",
    "ERRAVGdc, ERRSTDdc = cross_validate_c_vals(\n",
    "\tXtrain_norm, ytrain_bin_label, n_folds, c_vals, d_vals)\n",
    "\n",
    "plot_cross_val_err_vs_c(ERRAVGdc, ERRSTDdc, c_vals, d_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc12a4d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ytrain_bin_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 26\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m########################\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mBelow are the vectors evaluated by evaluate_c_d_pairs() function\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mERRAVGdcTEST - Average Testing error for each value of 'd'\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mImplement- evaluate_c_d_pairs(), plot_test_errors, plot_avg_support_vec(), plot_avg_violating_support_vec(), plot_avg_hyperplane_margins()\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     25\u001b[0m ERRAVGdcTEST, SuppVect, vmd, MarginT \u001b[39m=\u001b[39m evaluate_c_d_pairs(\n\u001b[0;32m---> 26\u001b[0m \tXtrain_norm, ytrain_bin_label, Xtest_norm, ytest_bin_label, n_folds, new_c_vals, d_vals)\n\u001b[1;32m     27\u001b[0m plot_test_errors(ERRAVGdcTEST, d_vals)\n\u001b[1;32m     29\u001b[0m \u001b[39m################\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m################\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m# Q3 d\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m################\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m################\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ytrain_bin_label' is not defined"
     ]
    }
   ],
   "source": [
    "################\n",
    "################\n",
    "# Q3 c\n",
    "################\n",
    "################\n",
    "d_vals = [1, 2, 3, 4]\n",
    "n_folds = 5\n",
    "'''\n",
    "Use the results from above and Fill the best c values for d=1,2,3,4\n",
    "'''\n",
    "########################\n",
    "## Your Solution Here ##\n",
    "new_c_vals = []\n",
    "########################\n",
    "\n",
    "'''\n",
    "Below are the vectors evaluated by evaluate_c_d_pairs() function\n",
    "ERRAVGdcTEST - Average Testing error for each value of 'd'\n",
    "SuppVect     - Average Number of Support Vectors for each value of 'd'\n",
    "vmd          - Average Number of Support Vectors that Violate the Margin for each value of 'd'\n",
    "MarginT      - Average Value of Hyperplane Margins for each value of 'd'\n",
    "Implement- evaluate_c_d_pairs(), plot_test_errors, plot_avg_support_vec(), plot_avg_violating_support_vec(), plot_avg_hyperplane_margins()\n",
    "'''\n",
    "\n",
    "ERRAVGdcTEST, SuppVect, vmd, MarginT = evaluate_c_d_pairs(\n",
    "\tXtrain_norm, ytrain_bin_label, Xtest_norm, ytest_bin_label, n_folds, new_c_vals, d_vals)\n",
    "plot_test_errors(ERRAVGdcTEST, d_vals)\n",
    "\n",
    "################\n",
    "################\n",
    "# Q3 d\n",
    "################\n",
    "################\n",
    "plot_avg_support_vec(SuppVect, d_vals)\n",
    "plot_avg_violating_support_vec(vmd, d_vals)\n",
    "\n",
    "################\n",
    "################\n",
    "# Q3 e\n",
    "################\n",
    "################\n",
    "plot_avg_hyperplane_margins(MarginT, d_vals)\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
